{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">GNNs - Master in Deep Learning of UPM</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberéis descomentar esta celda si no disponéis del setup necesario para trabajar con Pytorch Geometric o si estáis en Colab :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# import torch\n",
    "\n",
    "# def format_pytorch_version(version):\n",
    "#   return version.split('+')[0]\n",
    "\n",
    "# TORCH_version = torch.__version__\n",
    "# TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "# def format_cuda_version(version):\n",
    "#   return 'cu' + version.replace('.', '')\n",
    "\n",
    "# CUDA_version = torch.version.cuda\n",
    "# CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "# !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "# !pip install pyg-lib           -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "# !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "# !pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "# !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "# !pip install torch-geometric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Module\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from torch_geometric.utils import from_networkx, to_networkx\n",
    "from torch_geometric.loader import NeighborLoader, ClusterData, ClusterLoader, GraphSAINTRandomWalkSampler, GraphSAINTNodeSampler, GraphSAINTEdgeSampler\n",
    "from torch_geometric.datasets import CitationFull, TUDataset\n",
    "from torch_geometric.nn import GIN, GCN, MLP, GAT, global_mean_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio propuesto: Clasificación a nivel de nodo\n",
    "\n",
    "Utilizaremos el dataset CiteSeer. Los nodos representan documentos y las aristas citaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets.planetoid import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='CiteSeer', name='CiteSeer', \n",
    "                    split='random', num_train_per_class=350, num_val=500, num_test=500)\n",
    "data = dataset[0] # Cogemos el primer y único grafo del dataset\n",
    "\n",
    "print(f\"Nodos: {dataset[0].num_nodes}\")\n",
    "print(f\"Aristas: {dataset[0].num_edges}\")\n",
    "print(f\"Características: {dataset.num_features}\")\n",
    "print(f\"Clases: {dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este dataset ya viene separado en train, validation y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train mask: {data.train_mask.sum()}\")\n",
    "print(f\"Val mask: {data.val_mask.sum()}\")\n",
    "print(f\"Test mask: {data.test_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "El objetivo de este ejercicio será la creación de un entorno de experimentación que nos permita comparar diferentes arquitecturas, métodos de sampleo y diferentes hiperparámetros.\n",
    "\n",
    "Para la comparación tendremos en cuenta 3 arquitecturas de GNNs como son:\n",
    "\n",
    "- GIN\n",
    "- GCN\n",
    "- GAT\n",
    "\n",
    "Las arquitecturas que generemos deberán tener como _encoder_ estas arquitecturas y deberán estar enfocadas a la tarea de clasificación a nivel de nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase NodeClassifier implementará un `Module` de PyTorch Geometric y recibirá en el `__init__`:\n",
    "1. `encoder` *: Siendo un `str` entre tres valores:\n",
    "    - 'GIN': el encoder del clasificador será un modelo GIN.\n",
    "    - 'GCN': el encoder del clasificador será un modelo GCN.\n",
    "    - 'GAT': el encoder del clasificador será un modelo GAT.\n",
    "2. `num_features` *: El número de características de los nodos del grafo.\n",
    "3. `num_classes` *: El número de clases que puede tener un nodo. \n",
    "4. `hidden_channels`:  La dimensión oculta del modelo, por defecto 32.\n",
    "5. `num_layers`: El número de capas (paso de mensajes) del encoder, por defecto 2.\n",
    "6. `dropout`: Un `float` que denote el dropout que se use en el encoder, por defecto 0.5.\n",
    "7. `act`: Un `str` que especifique la función de activación, por defecto 'relu'.\n",
    "8. `jk`: El jumping knowledge que se aplicará a la salida de la GNN, por defecto 'cat'.\n",
    "\n",
    "El diseño y parametrización de la cabeza de clasificación queda a elección del alumno, como recomendación (ya que no va a variar mucho los resultados) se puede dejar constante.\n",
    "\n",
    "La función `forward` deberá recibir los siguientes parámetros:\n",
    "- `self` *: ya que es una función de una clase python.\n",
    "- `x` *: las features de los nodos.\n",
    "- `edge_index` *: las aristas de los nodos.\n",
    "- `edge_weights`: opcionalmente pesos para las aristas, por defecto None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HINT: self.encoder = GIN(...) o GCN(...) y self.head = MLP(...)\n",
    "class NodeClassifier(Module):\n",
    "    def __init__(self,\n",
    "            ...\n",
    "        ):\n",
    "        super(NodeClassifier, self).__init__()\n",
    "        ...\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.encoder.reset_parameters()\n",
    "        self.head.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.encoder(x, edge_index, edge_weight)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos si se instancia bien realizando una inferencia con números random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = \"GCN\"\n",
    "num_features = dataset.num_features\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "x = torch.rand((data.num_nodes, num_features))\n",
    "edge_index = data.edge_index\n",
    "edge_weight = None\n",
    "\n",
    "classifier = NodeClassifier(encoder, num_features, num_classes)\n",
    "\n",
    "out = classifier(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "print(f\"X shape: {x.shape}\")\n",
    "print(f\"Edge shape: {edge_index.shape}\")\n",
    "print(f\"Output shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "A continuación vamos a crear una clase `NodeDataModule` que nos generará el dataloader en función de los siguientes parámetros:\n",
    "\n",
    "1. `data` *: el grafo.\n",
    "\n",
    "2. `sampling` *: que será un str entre los siguientes valores: \n",
    "    - 'graph_sage': instanciará el `NeighborLoader`.\n",
    "    - 'graph_saint_node': instanciará el `GraphSAINTNodeSampler`.\n",
    "    - 'graph_saint_edge': instanciará el `GraphSAINTEdgeSampler`.\n",
    "    - 'graph_saint_rw': instanciará el `GraphSAINTRandomWalkSampler`.\n",
    "\n",
    "3. `batch_size` *: el tamaño de cada sub-grafo.\n",
    "\n",
    "4. `**kwargs`: que será el resto de parámetros que necesite cada método en particular. \n",
    "\n",
    "Deberá en el propio `__init__` almacenar:\n",
    "\n",
    "1. `self.data`: el dataset.\n",
    "2. `self.sampling`: el método de sampling.\n",
    "3. `self.dataloader`: el dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeDataModule:\n",
    "    def __init__(self, data, sampling, batch_size, **kwargs):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos si funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_sage_loader = NodeDataModule(data, \"graph_sage\", batch_size=32, num_neighbors=[10, 10]).dataloader\n",
    "graph_saint_node_loader = NodeDataModule(data, \"graph_saint_node\", batch_size=32, sample_coverage=10).dataloader\n",
    "graph_saint_edge_loader = NodeDataModule(data, \"graph_saint_edge\", batch_size=32, sample_coverage=10).dataloader\n",
    "graph_saint_random_walk_loader = NodeDataModule(data, \"graph_saint_rw\", batch_size=32, sample_coverage=100, num_steps=5, walk_length=3).dataloader\n",
    "\n",
    "print(f'Primer batch GraphSAGE')\n",
    "for batch in graph_sage_loader:\n",
    "    print(f\"X shape: {batch.x.shape}\")\n",
    "    print(f\"Edge shape: {batch.edge_index.shape}\")\n",
    "    print(f\"Output shape: {classifier(batch.x, batch.edge_index).shape}\")\n",
    "    break\n",
    "print('-----------------------------------')\n",
    "\n",
    "print(f'Primer batch GraphSAINT Node')\n",
    "for batch in graph_saint_node_loader:\n",
    "    print(f\"X shape: {batch.x.shape}\")\n",
    "    print(f\"Edge shape: {batch.edge_index.shape}\")\n",
    "    print(f\"Output shape: {classifier(batch.x, batch.edge_index).shape}\")\n",
    "    break\n",
    "print('-----------------------------------')\n",
    "\n",
    "print(f'Primer batch GraphSAINT Edge')\n",
    "for batch in graph_saint_edge_loader:\n",
    "    print(f\"X shape: {batch.x.shape}\")\n",
    "    print(f\"Edge shape: {batch.edge_index.shape}\")\n",
    "    print(f\"Output shape: {classifier(batch.x, batch.edge_index).shape}\")\n",
    "    break\n",
    "print('-----------------------------------')\n",
    "\n",
    "print(f'Primer batch GraphSAINT Random Walk')\n",
    "for batch in graph_saint_random_walk_loader:\n",
    "    print(f\"X shape: {batch.x.shape}\")\n",
    "    print(f\"Edge shape: {batch.edge_index.shape}\")\n",
    "    print(f\"Output shape: {classifier(batch.x, batch.edge_index).shape}\")\n",
    "    break\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, vamos a crear la clase Trainer siguiendo un estilo similar al de PytorchLightning para el LightningModule. Los métodos a completar son los siguientes:\n",
    "\n",
    "1. `graph_sage_step`: deberá procesar un batch y computar la loss para ese mismo batch.\n",
    "2. `graph_saint_step`: deberá procesar un batch teniendo en cuenta los pesos que graph saint nos otorga y devolver la loss para ese mismo batch.\n",
    "3. `train`: se deberá gestionar que función de step utilizar dependiendo del método de sampling elegido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, module, datamodule):\n",
    "        self.module = module\n",
    "        self.datamodule = datamodule\n",
    "\n",
    "    def graph_sage_step(self, batch):\n",
    "        ...\n",
    "        return loss\n",
    "    \n",
    "    def graph_saint_step(self, batch):\n",
    "        ...\n",
    "        return loss\n",
    "\n",
    "    def validate(self):\n",
    "        self.module.eval()\n",
    "        data = self.datamodule.data\n",
    "        out = self.module(data.x, data.edge_index)\n",
    "        loss = CrossEntropyLoss()(out[data.val_mask], data.y[data.val_mask])\n",
    "        return loss.item()\n",
    "    \n",
    "    def test(self):\n",
    "        self.module.eval()\n",
    "        data = self.datamodule.data\n",
    "        out = self.module(data.x, data.edge_index)\n",
    "        y_pred = out.argmax(dim=1)[data.test_mask].tolist()\n",
    "        y_true = data.y[data.test_mask].tolist()\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        print(f\"Test F1 Score: {f1}\")\n",
    "        sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='g', cmap='Blues')\n",
    "        return f1\n",
    "\n",
    "    def train(self, optimizer, criterion, device, epochs=100, val_every=5):\n",
    "        self.module.train()\n",
    "\n",
    "        self.criterion = criterion # Lo necesitaremos para GraphSage\n",
    "\n",
    "        # TODO En función del método de sampling self.step_fn será graph_sage_step o graph_saint_step\n",
    "        ...\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for batch in self.datamodule.dataloader:\n",
    "                batch = batch.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss = self.step_fn(batch)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            loss = epoch_loss/len(self.datamodule.dataloader)\n",
    "            \n",
    "            if epoch % val_every == 0:\n",
    "                val_loss = self.validate()\n",
    "                print(f\"Epoch {epoch}: Loss {loss}, Val Loss {val_loss}\")\n",
    "\n",
    "        return self.module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función nos permitirá guardar como una cadena de texto los hiperparámetros del último experimento realizado. Por defecto se guardará con el f1 obtenido en el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_exp_as_string(hp, test_f1):\n",
    "    exp_dir = f\"experiments/{test_f1:.5f}.txt\"\n",
    "    os.makedirs(os.path.dirname(exp_dir), exist_ok=True)  # Asegura que la carpeta exista\n",
    "    hp_string = str(hp)  # Convierte el diccionario a string\n",
    "    with open(exp_dir, 'w') as f:  # Guarda como texto\n",
    "        f.write(hp_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "A experimentar!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {\n",
    "    'module_hp': {\n",
    "        'encoder': 'GIN',\n",
    "        'num_features': dataset.num_features,\n",
    "        'num_classes': dataset.num_classes,\n",
    "        'hidden_channels': 32,\n",
    "        'num_layers': 2,\n",
    "        'dropout': 0.5,\n",
    "        'act': 'relu',\n",
    "        'jk': 'cat'\n",
    "    },\n",
    "    'dataloader_hp': {\n",
    "        'sampling': 'graph_sage',\n",
    "        'batch_size': 32,\n",
    "        'kwargs': {\n",
    "            'num_neighbors': [10, 10]\n",
    "        }\n",
    "        # 'kwargs': {\n",
    "        #     'num_neighbors': [10, 10]\n",
    "        # }\n",
    "        # 'kwargs': {\n",
    "        #     'sample_coverage': 100, \n",
    "        #     'num_steps': 5, \n",
    "        #     'walk_length': 3\n",
    "        # }\n",
    "    },\n",
    "    'trainer_hp': {\n",
    "        'optimizer': {\n",
    "            'cls' : Adam,\n",
    "            'lr': 0.01,\n",
    "            'weight_decay': 5e-4\n",
    "        },\n",
    "        'criterion': CrossEntropyLoss,\n",
    "        'epochs': 10,\n",
    "        'val_every': 5,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    }\n",
    "}\n",
    "\n",
    "module = NodeClassifier(\n",
    "    hp['module_hp']['encoder'],\n",
    "    hp['module_hp']['num_features'],\n",
    "    hp['module_hp']['num_classes'],\n",
    "    hp['module_hp']['hidden_channels'],\n",
    "    hp['module_hp']['num_layers'],\n",
    "    hp['module_hp']['dropout'],\n",
    "    hp['module_hp']['act'],\n",
    "    hp['module_hp']['jk']\n",
    ")\n",
    "\n",
    "datamodule = NodeDataModule(\n",
    "    data,\n",
    "    hp['dataloader_hp']['sampling'],\n",
    "    hp['dataloader_hp']['batch_size'],\n",
    "    **hp['dataloader_hp']['kwargs']\n",
    ")\n",
    "\n",
    "optimizer_cls = hp['trainer_hp']['optimizer']['cls']\n",
    "lr = hp['trainer_hp']['optimizer']['lr']\n",
    "weight_decay = hp['trainer_hp']['optimizer']['weight_decay']\n",
    "\n",
    "optimizer = optimizer_cls(module.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = hp['trainer_hp']['criterion']()\n",
    "device = hp['trainer_hp']['device']\n",
    "epochs = hp['trainer_hp']['epochs']\n",
    "val_every = hp['trainer_hp']['val_every']\n",
    "\n",
    "trainer = Trainer(module, datamodule)\n",
    "\n",
    "module = trainer.train(optimizer, criterion, device, epochs=epochs, val_every=val_every)\n",
    "test_f1 = trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_exp_as_string(hp, test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
